{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBB5hXGmiQrD"
   },
   "source": [
    "### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6083,
     "status": "ok",
     "timestamp": 1754039228968,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "Wz3muYudaTK6",
    "outputId": "1887349a-ce93-446c-e0a9-c08d3b6dbd7a"
   },
   "outputs": [],
   "source": [
    "from future_engineering import merge_dataframe, future_engineering\n",
    "\n",
    "from modeling import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1754039228993,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "G4J-I6sKZAwg"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1754039228999,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "5v4FBOQYaTPC"
   },
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis Libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1754039229003,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "0F4J6dH4iFw5"
   },
   "outputs": [],
   "source": [
    "#Statistical Valuator\n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXgIY1zCsLuz"
   },
   "source": [
    "### IMPORTING DATA AND RUNNING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1754039229997,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "cb6_Nv61sLnn"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['date'])\n",
    "oil = pd.read_csv('oil.csv', parse_dates=['date'])\n",
    "holidays = pd.read_csv('holidays_events.csv', parse_dates=['date'])\n",
    "transactions = pd.read_csv('transactions.csv', parse_dates=['date'])\n",
    "stores = pd.read_csv('stores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "error",
     "timestamp": 1754039230023,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "P-_NS7T9sXuO",
    "outputId": "b9dfe7c2-fd13-425d-abc4-3de576964280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after merges: (3029400, 13)\n"
     ]
    }
   ],
   "source": [
    "df = merge_dataframe(train, test, oil, holidays, transactions, stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1754039230029,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "WEnvzlmFsX1I"
   },
   "outputs": [],
   "source": [
    "df = future_engineering(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 7319,
     "status": "aborted",
     "timestamp": 1754039230032,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "TO7KmOHrwqsi"
   },
   "outputs": [],
   "source": [
    "model, X_val, y_val, X_test = train_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "516fbc79"
   },
   "source": [
    "### SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7322,
     "status": "aborted",
     "timestamp": 1754039230035,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "4dab1d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSLE: 1.2386956788053445\n"
     ]
    }
   ],
   "source": [
    "# Validation performance\n",
    "val_pred = model.predict(X_val)\n",
    "rmsle = np.sqrt(mean_squared_log_error(y_val, np.maximum(0, val_pred)))\n",
    "print(\"Validation RMSLE:\", rmsle)\n",
    "\n",
    "#Generate Submission\n",
    "# Predict on test set\n",
    "test['sales'] = np.maximum(0, model.predict(X_test))\n",
    "\n",
    "# Create submission\n",
    "submission = test[['id', 'sales']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1754039230039,
     "user": {
      "displayName": "Pedro Isaia Alves de Souza",
      "userId": "02292677914546630569"
     },
     "user_tz": 180
    },
    "id": "UPVDd406aTtk"
   },
   "outputs": [],
   "source": [
    "def merge_features(df, oil, holidays, transactions, stores):\n",
    "\n",
    "  # --- Merge Oil Prices ---\n",
    "  oil['dcoilwtico'] = oil['dcoilwtico'].ffill()\n",
    "  df = df.merge(oil, on='date', how='left')\n",
    "\n",
    "  # --- Merge Holidays ---\n",
    "  # Ensure 'date' column in holidays is datetime type before merging\n",
    "  holidays['date'] = pd.to_datetime(holidays['date'])\n",
    "  # Filter holidays to include only those present in the main dataframe's date range\n",
    "  holidays_filtered = holidays[holidays['date'].isin(df['date'].unique())]\n",
    "  # Create a column 'is_holiday' to indicate if a date is a holiday\n",
    "  holidays_filtered['is_holiday'] = 1\n",
    "  # Select only 'date' and 'is_holiday' columns and drop duplicates based on 'date'\n",
    "  holidays_processed = holidays_filtered[['date', 'is_holiday']].drop_duplicates(subset='date')\n",
    "  # Merge with the main dataframe\n",
    "  df = df.merge(holidays_processed, on='date', how='left')\n",
    "  # Fill NaN values in 'is_holiday' with 0, indicating non-holidays\n",
    "  df['is_holiday'] = df['is_holiday'].fillna(0)\n",
    "\n",
    "  # --- Merge Transactions ---\n",
    "  # Ensure 'date' column in transactions is datetime type before merging\n",
    "  transactions['date'] = pd.to_datetime(transactions['date'])\n",
    "  # Filter transactions to include only those present in the main dataframe's date and store_nbr combinations\n",
    "  transactions_filtered = transactions[transactions.set_index(['date', 'store_nbr']).index.isin(df.set_index(['date', 'store_nbr']).index)]\n",
    "  # Select only 'date', 'store_nbr', and 'transactions' columns and drop duplicates\n",
    "  transactions_processed = transactions_filtered[['date', 'store_nbr', 'transactions']].drop_duplicates(subset=['date', 'store_nbr'])\n",
    "  # Merge with the main dataframe\n",
    "  df = df.merge(transactions_processed, on=['date', 'store_nbr'], how='left')\n",
    "  # Fill NaN values in 'transactions' with 0\n",
    "  df['transactions'] = df['transactions'].fillna(0)\n",
    "\n",
    "\n",
    "  # --- Merge Store Metadata ---\n",
    "  # Select only 'store_nbr', 'city', 'state', and 'type' columns from the stores dataframe\n",
    "  stores_processed = stores[['store_nbr', 'city', 'state', 'type']].drop_duplicates(subset='store_nbr')\n",
    "  # Merge with the main dataframe\n",
    "  df = df.merge(stores_processed, on='store_nbr', how='left')\n",
    "\n",
    "\n",
    "  print(\"Dataset shape after merges:\", df.shape)\n",
    "\n",
    "  return df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNZI27TE0WJGmeqht2a+3NB",
   "collapsed_sections": [
    "tXgIY1zCsLuz",
    "516fbc79"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}


